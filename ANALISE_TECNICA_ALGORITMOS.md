# ğŸ“Š AnÃ¡lise TÃ©cnica dos Algoritmos Implementados

## 1. Algoritmo de EleiÃ§Ã£o Bully

### ğŸ“ DescriÃ§Ã£o
O algoritmo Bully Ã© usado para eleger um coordenador entre os servidores. O servidor com o maior ID sempre se torna o coordenador.

### ğŸ”„ Funcionamento

```
Estado Inicial:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Server #1 â”‚  â”‚Server #2 â”‚  â”‚Server #3 â”‚
â”‚  ID: 1   â”‚  â”‚  ID: 2   â”‚  â”‚  ID: 3   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Passo 1: Server #1 inicia eleiÃ§Ã£o
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Server #1 envia ELECTION para todos com ID maior
    ELECTION|1|clock
         â†“
    [Server #2]
    [Server #3]

Passo 2: Servidores maiores respondem
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Server #2 â†’ OK|2|clock â†’ Server #1
Server #3 â†’ OK|3|clock â†’ Server #1

Passo 3: Servidores maiores iniciam prÃ³pria eleiÃ§Ã£o
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Server #2 envia ELECTION para #3
Server #3 responde OK para #2

Passo 4: Server #3 (maior ID) se elege
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Server #3 â†’ COORDINATOR|3|clock â†’ Todos

Resultado Final:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Server #1 â”‚  â”‚Server #2 â”‚  â”‚Server #3 â”‚
â”‚ Membro   â”‚  â”‚ Membro   â”‚  â”‚COORDENADORâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ’» CÃ³digo Implementado

```java
private void startElection() {
    log("=== INICIANDO ELEIÃ‡ÃƒO BULLY ===");
    incrementClock(); // Incrementa relÃ³gio de Lamport
    
    boolean sentElection = false;
    // Envia ELECTION apenas para IDs maiores
    for (Integer otherId : serverAddresses.keySet()) {
        if (otherId > serverId) {
            sendToServer(otherId, "ELECTION|" + serverId + "|" + lamportClock);
            sentElection = true;
        }
    }
    
    if (!sentElection) {
        // Nenhum servidor com ID maior â†’ sou o coordenador
        becomeCoordinator();
    } else {
        // Aguarda resposta OK por 2 segundos
        // Se timeout, me torno coordenador
    }
}
```

### ğŸ“Š Complexidade
- **Mensagens no pior caso**: O(nÂ²)
- **Tempo de convergÃªncia**: O(n) Ã— timeout
- **EspaÃ§o**: O(n) para armazenar IDs dos servidores

### âš¡ Vantagens
- Sempre elege o servidor com maior capacidade (maior ID)
- Simples de implementar
- RÃ¡pida convergÃªncia em cenÃ¡rios normais

### âš ï¸ Desvantagens
- Muitas mensagens se eleiÃ§Ãµes sÃ£o frequentes
- Pode ter overhead se falhas sÃ£o comuns
- Servidor com maior ID se torna ponto de contenÃ§Ã£o

---

## 2. Algoritmo Ricart-Agrawala (ExclusÃ£o MÃºtua)

### ğŸ“ DescriÃ§Ã£o
Algoritmo distribuÃ­do para garantir que apenas um servidor acesse a seÃ§Ã£o crÃ­tica (placar) por vez, sem usar um coordenador central.

### ğŸ”„ Funcionamento

```
CenÃ¡rio: 3 servidores querem atualizar o placar

Estado Inicial:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Server #1 â”‚  â”‚Server #2 â”‚  â”‚Server #3 â”‚
â”‚ Clock: 5 â”‚  â”‚ Clock: 7 â”‚  â”‚ Clock: 3 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Passo 1: Server #1 solicita CS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Server #1:
  - incrementClock() â†’ clock = 6
  - requestTimestamp = 6
  - Envia CS_REQUEST|1|6 para todos

    CS_REQUEST|1|6
          â†“
    [Server #2]
    [Server #3]

Passo 2: Servidores decidem responder ou enfileirar
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Server #2 (clock=7):
  - NÃ£o estÃ¡ em CS
  - Responde: CS_REPLY|2|8

Server #3 (clock=3):
  - NÃ£o estÃ¡ em CS
  - Responde: CS_REPLY|3|4

Passo 3: Server #1 recebe todos os REPLYs
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Server #1:
  - Recebeu 2 REPLYs (de #2 e #3)
  - Total esperado: 2
  - âœ… Entra na seÃ§Ã£o crÃ­tica!
  - Atualiza placar
  - Sai da CS

Passo 4: Processa requisiÃ§Ãµes enfileiradas
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Se outros servidores enviaram REQUEST enquanto #1 
estava em CS, agora #1 responde a eles.

Caso de Conflito:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Server #1: REQUEST com timestamp 6
Server #2: REQUEST com timestamp 6 (mesmo timestamp!)

Desempate por ID:
  - Server #1 tem prioridade (ID menor)
  - Server #2 enfileira o REQUEST
  - Server #1 entra na CS primeiro
```

### ğŸ’» CÃ³digo Implementado

```java
private void requestCriticalSection(Runnable criticalSection) {
    new Thread(() -> {
        incrementClock();
        requestingCS = true;
        requestTimestamp = lamportClock;
        replyReceived.clear();
        
        // Enviar REQUEST para todos
        for (Integer otherId : serverAddresses.keySet()) {
            sendToServer(otherId, "CS_REQUEST|" + serverId + "|" + requestTimestamp);
        }
        
        // Aguardar REPLY de todos (com timeout)
        while (replyReceived.size() < serverAddresses.size() && timeout < 50) {
            Thread.sleep(100);
        }
        
        // Executar seÃ§Ã£o crÃ­tica
        criticalSection.run();
        
        requestingCS = false;
        processQueuedRequests(); // Responder pedidos enfileirados
    }).start();
}

// Ao receber CS_REQUEST
case "CS_REQUEST":
    int reqTime = Integer.parseInt(parts[2]);
    
    // Se estou pedindo CS e tenho prioridade, enfileiro
    if (requestingCS && (reqTime < requestTimestamp || 
        (reqTime == requestTimestamp && reqId < serverId))) {
        requestQueue.add(new MutexRequest(reqId, reqTime));
    } else {
        // Respondo imediatamente
        sendToServer(reqId, "CS_REPLY|" + serverId + "|" + lamportClock);
    }
```

### ğŸ“Š Complexidade
- **Mensagens por entrada na CS**: 2(n-1)
  - (n-1) REQUESTs
  - (n-1) REPLYs
- **Tempo de espera**: RTT (Round Trip Time)
- **EspaÃ§o**: O(n) para fila de requisiÃ§Ãµes

### âš¡ Vantagens
- NÃ£o precisa de coordenador central
- Baixa latÃªncia (1 RTT)
- Fairness por timestamp (FIFO se relÃ³gios sincronizados)

### âš ï¸ Desvantagens
- Precisa de comunicaÃ§Ã£o com TODOS os servidores
- Um servidor falho bloqueia o sistema
- Overhead de mensagens aumenta com nÂ²

---

## 3. ConsistÃªncia de RÃ©plicas

### ğŸ“ DescriÃ§Ã£o
Garante que todos os servidores tenham o mesmo estado do jogo (placar, pergunta atual, status).

### ğŸ”„ Funcionamento

```
CenÃ¡rio: Cliente responde corretamente no Server #1

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Cliente Aâ”‚â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ ANSWER|0
              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚Server #1 â”‚
        â”‚          â”‚
        â”‚ 1. Atualiza placar local
        â”‚    globalScoreboard.put("Alice", 100)
        â”‚
        â”‚ 2. Replica para outros servidores
        â”‚    REPLICATE|SCORE_UPDATE|Alice:100|clock
        â”‚
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
       â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
       â”‚            â”‚
       â–¼            â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚Server #2 â”‚  â”‚Server #3 â”‚
  â”‚          â”‚  â”‚          â”‚
  â”‚ Recebe:  â”‚  â”‚ Recebe:  â”‚
  â”‚ REPLICATEâ”‚  â”‚ REPLICATEâ”‚
  â”‚          â”‚  â”‚          â”‚
  â”‚ Atualiza:â”‚  â”‚ Atualiza:â”‚
  â”‚ Alice=100â”‚  â”‚ Alice=100â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Resultado: Estado consistente em todos!
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Server #1 â”‚  â”‚Server #2 â”‚  â”‚Server #3 â”‚
â”‚Alice: 100â”‚  â”‚Alice: 100â”‚  â”‚Alice: 100â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ’» CÃ³digo Implementado

```java
private void syncScoreboard(String playerName, int score) {
    // Usa Ricart-Agrawala para exclusÃ£o mÃºtua
    requestCriticalSection(() -> {
        // Atualiza localmente
        globalScoreboard.put(playerName, score);
        log("Placar atualizado: " + playerName + " = " + score);
        
        // Replica para outros servidores
        replicateGameState("SCORE_UPDATE", playerName + ":" + score);
    });
}

private void replicateGameState(String action, String data) {
    incrementClock();
    String message = "REPLICATE|" + action + "|" + data + "|" + lamportClock;
    
    // Broadcast para todos os servidores
    for (Integer otherId : serverAddresses.keySet()) {
        sendToServer(otherId, message);
    }
}

private void handleReplication(String action, String data) {
    switch (action) {
        case "SCORE_UPDATE":
            String[] scoreData = data.split(":");
            globalScoreboard.put(scoreData[0], Integer.parseInt(scoreData[1]));
            log("Placar replicado: " + scoreData[0] + " = " + scoreData[1]);
            break;
        // ... outros tipos de replicaÃ§Ã£o
    }
}
```

### ğŸ“Š Modelo de ConsistÃªncia
- **Tipo**: ConsistÃªncia Sequencial
- **Garantia**: Todas as rÃ©plicas veem as operaÃ§Ãµes na mesma ordem
- **SincronizaÃ§Ã£o**: Combinado com Ricart-Agrawala para atomicidade

### âš¡ Vantagens
- Estado sempre sincronizado
- Clientes podem conectar a qualquer servidor
- TolerÃ¢ncia a falhas (estado replicado)

### âš ï¸ Desvantagens
- LatÃªncia de replicaÃ§Ã£o
- Overhead de mensagens
- Potencial inconsistÃªncia temporÃ¡ria

---

## 4. RelÃ³gios LÃ³gicos de Lamport

### ğŸ“ DescriÃ§Ã£o
Ordena eventos em sistema distribuÃ­do sem relÃ³gio fÃ­sico sincronizado.

### ğŸ”„ Funcionamento

```
CenÃ¡rio: Troca de mensagens entre servidores

Server #1          Server #2          Server #3
Clock: 5           Clock: 3           Clock: 8
   â”‚                  â”‚                  â”‚
   â”‚ Evento local     â”‚                  â”‚
   â”‚ clock++          â”‚                  â”‚
   â”‚ clock = 6        â”‚                  â”‚
   â”‚                  â”‚                  â”‚
   â”‚ MSG|6            â”‚                  â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                  â”‚
   â”‚                  â”‚ Recebe MSG|6     â”‚
   â”‚                  â”‚ clock = max(3,6)+1
   â”‚                  â”‚ clock = 7        â”‚
   â”‚                  â”‚                  â”‚
   â”‚                  â”‚ MSG|7            â”‚
   â”‚                  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
   â”‚                  â”‚                  â”‚ Recebe MSG|7
   â”‚                  â”‚                  â”‚ clock = max(8,7)+1
   â”‚                  â”‚                  â”‚ clock = 9
   â”‚                  â”‚                  â”‚
   â”‚                  â”‚      MSG|9       â”‚
   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ Recebe MSG|9     â”‚                  â”‚
   â”‚ clock = max(6,9)+1                  â”‚
   â”‚ clock = 10       â”‚                  â”‚

Ordem Global de Eventos:
1. Server #1 envia (timestamp=6)
2. Server #2 recebe (timestamp=7)
3. Server #2 envia (timestamp=7)
4. Server #3 recebe (timestamp=9)
5. Server #3 envia (timestamp=9)
6. Server #1 recebe (timestamp=10)
```

### ğŸ’» CÃ³digo Implementado

```java
// RelÃ³gio de Lamport
private int lamportClock = 0;
private final Object clockLock = new Object();

// Incrementar ao gerar evento local
private void incrementClock() {
    synchronized (clockLock) {
        lamportClock++;
        updateClockDisplay();
    }
}

// Atualizar ao receber mensagem
private void updateClock(int receivedTime) {
    synchronized (clockLock) {
        lamportClock = Math.max(lamportClock, receivedTime) + 1;
        updateClockDisplay();
    }
}

// Uso em mensagens
private void sendMessage(String type, String data) {
    incrementClock(); // Evento: enviar mensagem
    String message = type + "|" + data + "|" + lamportClock;
    // ... enviar
}

private void receiveMessage(String message) {
    String[] parts = message.split("\\|");
    int receivedClock = Integer.parseInt(parts[parts.length - 1]);
    updateClock(receivedClock); // Atualizar relÃ³gio
    // ... processar mensagem
}
```

### ğŸ“Š Propriedades

**Propriedade 1: Causalidade**
```
Se evento A â†’ B (A causa B), entÃ£o LC(A) < LC(B)
```

**Propriedade 2: OrdenaÃ§Ã£o Parcial**
```
Se LC(A) < LC(B), A pode ter causado B (mas nÃ£o Ã© certeza)
Se LC(A) = LC(B), eventos sÃ£o concorrentes
```

**Uso no Sistema:**
1. Ordernar requisiÃ§Ãµes de CS (Ricart-Agrawala)
2. Detectar causalidade entre eventos
3. Debug e logging ordenado

### âš¡ Vantagens
- NÃ£o precisa sincronizar relÃ³gios fÃ­sicos
- Baixo overhead (apenas um inteiro)
- Captura causalidade entre eventos

### âš ï¸ Desvantagens
- NÃ£o ordena eventos concorrentes
- NÃ£o representa tempo real
- Pode crescer indefinidamente

---

## ğŸ“Š ComparaÃ§Ã£o dos Algoritmos

| Aspecto | Bully | Ricart-Agrawala | RÃ©plicas | Lamport |
|---------|-------|-----------------|----------|---------|
| **Mensagens** | O(nÂ²) | 2(n-1) | O(n) | 0 overhead |
| **Coordenador** | Sim | NÃ£o | NÃ£o | NÃ£o |
| **TolerÃ¢ncia a Falhas** | MÃ©dia | Baixa | Alta | N/A |
| **LatÃªncia** | Alta | Baixa | MÃ©dia | Zero |
| **Complexidade** | Baixa | MÃ©dia | Alta | Baixa |
| **Uso** | EleiÃ§Ã£o | Mutex | SincronizaÃ§Ã£o | OrdenaÃ§Ã£o |

---

## ğŸ¯ IntegraÃ§Ã£o dos Algoritmos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         SISTEMA INTEGRADO               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  1. Lamport Clock                       â”‚
â”‚     â†“ (Ordena todos os eventos)         â”‚
â”‚                                         â”‚
â”‚  2. Bully Election                      â”‚
â”‚     â†“ (Elege coordenador)               â”‚
â”‚                                         â”‚
â”‚  3. Ricart-Agrawala                     â”‚
â”‚     â†“ (Protege seÃ§Ã£o crÃ­tica)           â”‚
â”‚                                         â”‚
â”‚  4. ReplicaÃ§Ã£o                          â”‚
â”‚     â†“ (MantÃ©m consistÃªncia)             â”‚
â”‚                                         â”‚
â”‚  Resultado: Sistema distribuÃ­do         â”‚
â”‚            confiÃ¡vel e consistente      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fluxo TÃ­pico:**
1. Sistema inicia â†’ **Bully** elege coordenador
2. Cliente responde â†’ Servidor usa **Lamport** para timestamp
3. Atualizar placar â†’ **Ricart-Agrawala** garante exclusÃ£o mÃºtua
4. ApÃ³s atualizaÃ§Ã£o â†’ **ReplicaÃ§Ã£o** sincroniza todos os servidores

---

## ğŸ”¬ Experimentos Sugeridos

### Experimento 1: Performance da EleiÃ§Ã£o
- Medir tempo de eleiÃ§Ã£o com 2, 3, 5, 10 servidores
- Contar mensagens trocadas
- Analisar overhead

### Experimento 2: ContenÃ§Ã£o em CS
- Simular 3 servidores tentando CS simultaneamente
- Medir tempo de espera de cada um
- Verificar fairness (ordem FIFO?)

### Experimento 3: LatÃªncia de ReplicaÃ§Ã£o
- Medir tempo entre atualizaÃ§Ã£o local e rÃ©plica
- Testar com diferentes nÃºmeros de servidores
- Verificar impacto na experiÃªncia do usuÃ¡rio

### Experimento 4: TolerÃ¢ncia a Falhas
- Simular falha do coordenador durante jogo
- Medir tempo de recuperaÃ§Ã£o
- Verificar perda de dados

---

## ğŸ’¡ Melhorias Futuras

1. **OtimizaÃ§Ã£o do Bully**: Implementar anel lÃ³gico para reduzir mensagens
2. **Ricart-Agrawala com Quorum**: Apenas maioria precisa responder
3. **ReplicaÃ§Ã£o AssÃ­ncrona**: Melhorar performance com eventual consistency
4. **Vector Clocks**: Substituir Lamport para capturar mais causalidade
5. **Heartbeat**: Detectar falhas mais rapidamente